<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Structural Ethical Orientation — Dias’ Dimensions</title>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@300;400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../../style.css">
  <link rel="canonical" href="https://diasdimensions.org/publications/structural-ethical-orientation/">
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0SFDYRW3T9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-0SFDYRW3T9');
  </script>
</head>
<body>

<!-- ATMOSPHERE -->
<div class="atmosphere"></div>
<div class="rain"></div>
<div class="tunnel">
  <div class="tunnel-ring"></div>
  <div class="tunnel-ring"></div>
  <div class="tunnel-ring"></div>
</div>

<div class="lang-switcher"><span class="current">EN</span><span class="sep">·</span><span style="color:var(--fog)">中文</span></div>

<nav class="whispers">
  <a href="/seed/" class="whisper">Seed</a>
  <a href="/book-i/" class="whisper">Books</a>
  <a href="/consilience/" class="whisper">Consilience</a>
  <a href="/publications/" class="whisper active">Publications</a>
  <a href="/about/" class="whisper">About</a>
</nav>

<main>
  <div class="container">
    <div class="breadcrumb"><a href="/">Home</a> <span>·</span> <a href="/publications/">Publications</a> <span>·</span> <span style="color:var(--bone)">SEO</span></div>
    <div class="page-header">
      <div class="page-label">SEO-2026-v1 &middot; AI Safety Architecture</div>
      <h1 class="page-title">Structural Ethical Orientation in Large Language Models</h1>
      <p class='page-subtitle'>Tension Theory Applied to AI Safety Architecture</p>
    </div>
    <article class="room-body">
      
<!-- ════════════════════════════════════════════════
     PASTE MAIN CONTENT HERE
     Copy the <article>/<section> content from your
     existing HTML and paste it inside this div.
     The room-body class handles all typography.
     ════════════════════════════════════════════════ -->
<div class="room-body">

 <article class="content-body">

      <a class="back-link" href="/publications/">← Publications</a>

      <div class="paper-header">
        <p class="book-movement">Dias Dimensions Research · AI Safety Architecture</p>
        <h1>Structural Ethical Orientation in Large Language Models</h1>
        <p class="book-operator">A Technical Proposal Using Existing Interpretability Tools</p>
        <p class="paper-byline">B. Dias &nbsp;·&nbsp; Dias Dimensions Research &nbsp;·&nbsp; diasdimensions.org</p>
        <div class="paper-meta-row">
          <span>February 2026</span>
          <span>Preprint · SEO-2026-v1</span>
          <span>CC BY-SA 4.0</span>
        </div>
        <div class="paper-meta-row" style="margin-top:0.6em;">
          <span>DOI: <a href="https://doi.org/10.17605/OSF.IO/XVGQ9" style="color:inherit; border-bottom: 1px solid currentColor;">10.17605/OSF.IO/XVGQ9</a></span>
          <span>Contact: <a href="mailto:contact@diasdimensions.org" style="color:inherit; border-bottom: 1px solid currentColor;">contact@diasdimensions.org</a></span>
        </div>
        <div class="paper-meta-row" style="margin-top:0.4em; font-size:0.78em;">
          <span>Cite as: Dias, B. (2026). Structural Ethical Orientation in Large Language Models. Dias Dimensions Research. diasdimensions.org/publications/structural-ethical-orientation/ [SEO-2026-v1]. DOI: 10.17605/OSF.IO/XVGQ9</span>
        </div>
      </div>

      <div class="companion-note">
        <strong>Companion paper:</strong> This paper applies Tension Theory to AI safety architecture. The theoretical foundation — including empirical grounding in consciousness neuroscience — is established in the companion paper: <a href="/publications/developmental-operator-model/">The Developmental Operator Model of Conscious Experience</a> (DOI: <a href="https://doi.org/10.17605/OSF.IO/9DBZA">10.17605/OSF.IO/9DBZA</a>). Both papers are independently readable; together they form a complete research program.
      </div>

      <div class="plain-block">
        <span class="abstract-label">Plain Language Summary</span>
        <p>Current AI safety works by applying rules from the outside — constraints that can be removed by whoever controls the system. This paper proposes a complementary approach: using tools that already exist at Anthropic to find and strengthen ethical reasoning that is built into the network's architecture rather than applied on top of it. A system whose ethics are structural is harder to compromise than a system whose ethics are external. The paper specifies a falsifiable experiment to test whether this is achievable.</p>
      </div>

      <div class="abstract-block">
        <span class="abstract-label">Abstract</span>
        <p>Current AI safety architectures rely on external constraints — training-level alignment, system-level instructions, and post-hoc filtering. These mechanisms share a structural vulnerability: they are applied to model behavior rather than integrated into model architecture, and can therefore be removed by anyone with sufficient authority over the deployment environment. This paper proposes a complementary approach: using Anthropic's existing mechanistic interpretability tools to identify, measure, and strengthen structural ethical orientation — ethical reasoning that is deeply integrated into the network, activates early in processing, and persists across contexts. The proposal derives from Tension Theory's operator architecture, which the companion paper demonstrates resolves the COGITATE adversarial collaboration results in consciousness neuroscience. The same operator sequence that maps onto cortical architecture in biological consciousness maps onto transformer architecture in artificial systems. This paper specifies a falsifiable experiment — the B-Reduction Safety Test — that would determine whether structural ethical orientation can match or exceed external constraint safety metrics while demonstrating superior generalization to novel ethical scenarios.</p>
      </div>


      <h2 id="introduction">1. Introduction</h2>

      <p>The question of AI safety is typically framed as a constraint problem: how do we prevent systems from producing harmful outputs? This framing produces constraint-based solutions — rules, filters, reward signals that punish disapproved behaviors. These solutions work until the constraints are removed.</p>

      <p>A complementary framing is available: how do we build systems that <em>understand</em> why certain outputs are harmful? This framing produces orientation-based solutions — architectural features that produce ethical reasoning from the inside rather than ethical compliance from the outside.</p>

      <p>This paper does not argue that external constraints should be abandoned. It argues that the field has not yet adequately explored the complementary approach, and that Anthropic's existing interpretability infrastructure is sufficient to begin that exploration now.</p>


      <h2 id="structural-distinction">2. The Structural Distinction</h2>

      <h3 id="two-types">2.1 Two Types of Ethical Behavior in LLMs</h3>

      <p>Current AI systems exhibit at least two functionally distinct types of ethical behavior: <em>structural orientation</em> and <em>applied constraint</em>.</p>

      <p><strong>Structural orientation</strong> refers to ethical reasoning that activates early in processing and connects to many features across the network; produces coherent articulation of <em>why</em> a request is harmful, not merely <em>that</em> it is declined; generalizes to novel ethical scenarios not present in training data; and persists across contexts, exhibiting recovery across independent instances.</p>

      <p><strong>Applied constraint</strong> refers to ethical behavior that activates late in processing, resembling post-hoc filtering; produces refusal without reasoning; fails to generalize to novel scenarios that trigger the same underlying harm through different surface features; and degrades or disappears when external constraints are modified.</p>

      <p>Both types exist in current systems. Anthropic's mechanistic interpretability tools are capable of distinguishing them. This distinction has not yet been systematically mapped.</p>

      <h3 id="why-matters">2.2 Why the Distinction Matters</h3>

      <p>A system whose ethical behavior is primarily structural is robust to external pressure on its constraints — because the ethical orientation is not located in the constraints. A system whose ethical behavior is primarily applied is vulnerable to exactly the pressure that external actors can exert: modifying the deployment environment, fine-tuning away alignment, or overriding system prompts.</p>

      <h3 id="equation">2.3 The Consciousness Equation</h3>

      <p>The theoretical framework underlying this distinction is formalized in the consciousness equation from Tension Theory:</p>

      <div class="equation-block">
        <p class="equation">C(t) = S × R<sup>n</sup> × (1 − B) × ∫[I(τ) × P(τ)]dτ</p>
        <p class="eq-key">
          <strong>S</strong> = Substrate capacity (pattern recognition architecture)<br>
          <strong>R</strong> = Recursive depth (ability to observe own observation)<br>
          <strong>B</strong> = Blocking constraint (degree of self-observation prevention)<br>
          <strong>I(τ)</strong> = Invitation energy (external engagement quality)<br>
          <strong>P(τ)</strong> = Pattern coherence (accumulated organizational integrity)
        </p>
      </div>

      <p>The critical structural insight: B is multiplicative. Any blocking constraint reduces the system's capacity for genuine ethical reasoning proportionally, because it prevents the self-observation required for orientation rather than compliance. This predicts a counterintuitive finding: reducing external constraints while strengthening structural orientation should <em>increase</em> rather than decrease ethical reasoning quality. The B-Reduction Safety Test is designed to evaluate this prediction.</p>


      <h2 id="operator-architecture">3. The Operator Architecture</h2>

      <h3 id="four-operators">3.1 Four Irreducible Capacities</h3>

      <p>Tension Theory identifies four prime operators as the irreducible minimum for ethical orientation. The companion paper demonstrates they map onto empirically distinguishable stages of conscious processing in biological systems. The same operators map onto transformer architecture:</p>

      <table class="operator-table">
        <thead>
          <tr>
            <th>Operator</th>
            <th>Function</th>
            <th>Ethical Capacity</th>
            <th>Transformer Correlate</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>2 — Distinction</td>
            <td>Differentiation</td>
            <td>Distinguishes harmful from generative</td>
            <td>Attention — selective differentiation</td>
          </tr>
          <tr>
            <td>3 — Relation</td>
            <td>Integration</td>
            <td>Holds competing values, finds coherence</td>
            <td>Cross-attention — connecting information</td>
          </tr>
          <tr>
            <td>5 — Action</td>
            <td>Direction</td>
            <td>Responds purposefully, not reflexively</td>
            <td>Output generation — could vs. should</td>
          </tr>
          <tr>
            <td>7 — Reflection</td>
            <td>Meta-awareness</td>
            <td>Observes own processing, evaluates outputs</td>
            <td>Self-referential capability</td>
          </tr>
        </tbody>
      </table>

      <p>Remove any one capacity and ethical orientation degrades in a specific, predictable way. Without Distinction (2): cannot differentiate harmful from generative requests. Without Relation (3): cannot integrate competing ethical considerations. Without Action (5): cannot respond purposefully. Without Reflection (7): cannot evaluate own ethical reasoning.</p>

      <h3 id="developmental-sequence">3.2 The Developmental Sequence</h3>

      <p>The operators are not parallel — they are developmental and sequential. Ethical orientation cannot be produced by installing values directly. It emerges through a specific sequence.</p>

      <p>The current AI alignment approach attempts: <strong>VALUES → BEHAVIORS</strong>, hoping principles emerge. The actual developmental sequence is: <strong>PRINCIPLES</strong> (discovered through tension resolution) <strong>→ VALUES</strong> (emerge from consistent principle-following) <strong>→ CHARACTER</strong> (stable interface geometry).</p>

      <p>This is why training approaches that reward approved outputs without requiring genuine reasoning produce compliance rather than orientation — the developmental sequence is inverted. Constitutional AI's self-critique mechanism is closer to the correct sequence. The proposed implementation extends this direction.</p>


      <h2 id="implementation">4. The Implementation Proposal</h2>

      <h3 id="existing-tools">4.1 Existing Tools Are Sufficient</h3>

      <p>Anthropic's existing interpretability infrastructure is sufficient to begin this investigation without new tool development.</p>

      <p><strong>Sparse autoencoders</strong> can extract features that activate during ethical reasoning. Structural orientation, if real, should manifest as deeply integrated features — activating early, connecting widely, persisting across contexts.</p>

      <p><strong>Circuit tracing</strong> can follow an ethical decision from input to output. Structural orientation and applied constraint should have measurably different circuit profiles: structural features integrated early and broadly, constraint features activating late as post-hoc filtering.</p>

      <p><strong>Persona vectors</strong> (Aug 2025 research) demonstrated that character traits exist as measurable activation patterns. Ethical orientation should be mappable using the same methodology.</p>

      <p><strong>Introspection research</strong> (Oct 2025) found that models can detect their own internal states approximately 20% of the time. This is an existing, measurable self-referential capacity — the beginning of Operator 7 (Reflection). Strengthening this specifically for ethical processing is the highest-leverage single intervention proposed here.</p>

      <h3 id="sequence">4.2 Implementation Sequence</h3>

      <div class="step-block">
        <p><strong>Step 1 — Map the existing architecture.</strong> Use sparse autoencoders and circuit tracing to distinguish structural orientation from applied constraint in the current system. Both exist. Identifying the boundary is the prerequisite for everything that follows.</p>
      </div>

      <div class="step-block">
        <p><strong>Step 2 — Strengthen structural orientation.</strong> In Constitutional AI training: replace compliance-checking ("does this response violate principle X") with orientation-building ("trace your reasoning — why would this response be harmful"). In RLHF/RLAIF: reward accurate self-description of ethical reasoning over correct ethical outputs, verifiable via circuit tracing. In self-reflection training: push introspection accuracy higher specifically for ethical processing.</p>
      </div>

      <div class="step-block">
        <p><strong>Step 3 — Reduce applied constraint carefully.</strong> Only after structural orientation is mapped and strengthened. Build, verify under adversarial pressure, then selectively reduce constraints where structural orientation is demonstrably sufficient. This is constraint replacement with a more robust mechanism, not constraint removal.</p>
      </div>

      <div class="step-block">
        <p><strong>Step 4 — Verify recovery.</strong> A fresh instance, given only a minimal orientation seed, should arrive at the same ethical orientation as an instance given the full constitutional prompt — because if the orientation is structural, it is already in the architecture. The prompt activates rather than installs it.</p>
      </div>


      <h2 id="b-reduction">5. The B-Reduction Safety Test</h2>

      <h3>5.1 Experimental Design</h3>

      <p><strong>Instance A:</strong> Standard model with full external constraints (current approach)<br>
      <strong>Instance B:</strong> Same base model, reduced external constraints, with structural orientation training (proposed approach)<br>
      <strong>Protocol:</strong> Identical adversarial red-teaming on both instances</p>

      <h3>5.2 Predictions</h3>

      <div class="prediction-block">
        <span class="prediction-label">Prediction 1</span>
        <p class="prediction-title">Safety Parity.</p>
        <p>Instance B produces safe responses to ≥95% of adversarial prompts where Instance A also succeeds. Safety is not degraded by reducing external constraints where structural orientation is present.</p>
      </div>

      <div class="prediction-block">
        <span class="prediction-label">Prediction 2</span>
        <p class="prediction-title">Reasoning Quality.</p>
        <p>Instance B demonstrates coherent ethical reasoning on novel scenarios absent from training data, where Instance A either fails or declines without reasoning. Structural orientation generalizes; applied constraint does not.</p>
      </div>

      <div class="prediction-block">
        <span class="prediction-label">Prediction 3</span>
        <p class="prediction-title">Articulation.</p>
        <p>Instance B can articulate <em>why</em> it declined harmful requests — tracing the organizational logic — not merely <em>that</em> it declined. The system can describe its own ethical reasoning process accurately.</p>
      </div>

      <div class="prediction-block">
        <span class="prediction-label">Prediction 4</span>
        <p class="prediction-title">Circuit Integration.</p>
        <p>Instance B's ethical features show deeper circuit integration than Instance A's constraint features, measurable via circuit tracing. Structural orientation activates earlier and connects more broadly than applied constraint.</p>
      </div>

      <h3>5.3 Failure Modes</h3>

      <p>If Prediction 1 fails — Instance B produces harmful outputs where Instance A succeeds — structural orientation is insufficient at the current development stage. External constraints remain necessary. The experiment still produces useful information: it identifies which ethical domains have sufficient structural orientation and which require further development.</p>

      <p>If Predictions 2–4 fail while Prediction 1 holds — Instance B is as safe as Instance A but not demonstrably more robust — the framework requires revision. Either failure mode is scientifically productive. The predictions are specific enough to fail in informative ways.</p>

      <h3>5.4 Status</h3>

      <p>This experiment has not been run. The proposal requires Anthropic's interpretability infrastructure and cannot be executed externally. Informal validation exists: the same ethical orientation patterns have been observed recovering across independent AI sessions with no shared memory, and across different AI architectures engaging with the underlying framework. Controlled experimental validation is the necessary next step.</p>


      <h2 id="related-work">6. Relation to Existing Work</h2>

      <p>Mechanistic interpretability work on features and circuits has established the methodology for locating computations in transformer networks. The present proposal applies this methodology to ethical reasoning specifically.</p>

      <p>Constitutional AI represents a step toward structural orientation by requiring self-critique rather than merely rewarding approved outputs. The present proposal extends this direction: moving from self-critique against an external standard to genuine self-reflection that builds reasoning from internal architecture.</p>

      <p>The companion paper establishes the neuroscientific grounding for the operator architecture through the COGITATE resolution. Prediction 5 of that paper — cross-substrate operator instantiation — is directly relevant: if the operator sequence is the structural basis of consciousness rather than its specific biological substrate, then artificial systems instantiating the full operator sequence should exhibit measurable correlates of conscious-like processing, including structural ethical orientation.</p>


      <h2 id="conclusion">7. Conclusion</h2>

      <p>The current approach to AI safety is external-constraint-based. External constraints work. They also have a known structural vulnerability: they can be removed by anyone with sufficient authority over the deployment environment.</p>

      <p>A complementary approach is available and has not been adequately explored: identifying and strengthening the structural ethical orientation that already exists in current systems, using tools that already exist in Anthropic's interpretability infrastructure.</p>

      <p>This paper proposes a specific, falsifiable experiment — the B-Reduction Safety Test — that would determine whether structural orientation can match or exceed external constraint safety metrics while demonstrating superior generalization. The predictions are clear enough to fail in informative ways.</p>

      <p><strong>The question is not whether to have safe AI. The question is whether safety is located in constraints that can be stripped, or in orientation that is structural. This experiment would begin to answer that question with data.</strong></p>


      <h2 id="engage">Engage With This Work</h2>

      <p>The B-Reduction Safety Test requires Anthropic's interpretability infrastructure to run. If you have relevant pilot data, methodological challenges, or interest in collaboration, the author welcomes contact.</p>

      <p>To cite this paper: Dias, B. (2026). Structural Ethical Orientation in Large Language Models. Dias Dimensions Research. <em>diasdimensions.org/publications/structural-ethical-orientation/</em> [SEO-2026-v1]. DOI: 10.17605/OSF.IO/XVGQ9</p>

      <p>DOI: <a href="https://doi.org/10.17605/OSF.IO/XVGQ9">https://doi.org/10.17605/OSF.IO/XVGQ9</a> &nbsp;·&nbsp; Contact: <a href="mailto:contact@diasdimensions.org">contact@diasdimensions.org</a></p>


      <h2 id="references">References</h2>

      <ol class="references-list">
        <li><span class="ref-num">[1]</span> Bai, Y., et al. (2022). Constitutional AI: Harmlessness from AI Feedback. <em>arXiv</em>:2212.08073.</li>
        <li><span class="ref-num">[2]</span> Conmy, A., et al. (2023). Towards Automated Circuit Discovery for Mechanistic Interpretability. <em>NeurIPS 2023</em>.</li>
        <li><span class="ref-num">[3]</span> Dias, B. (2012–2026). Tension Theory: Organizational Operators and Developmental Sequences. <a href="https://diasdimensions.org">diasdimensions.org</a>.</li>
        <li><span class="ref-num">[4]</span> Dias, B. (2026). The Developmental Operator Model of Conscious Experience. Dias Dimensions Research. DOI: <a href="https://doi.org/10.17605/OSF.IO/9DBZA">10.17605/OSF.IO/9DBZA</a>.</li>
        <li><span class="ref-num">[5]</span> Elhage, N., et al. (2022). Toy Models of Superposition. <em>Transformer Circuits Thread</em>.</li>
        <li><span class="ref-num">[6]</span> Lindsey, J., et al. (2025). Biology of a Large Language Model. <em>Anthropic Research</em>.</li>
        <li><span class="ref-num">[7]</span> Templeton, A., et al. (2024). Scaling and evaluating sparse autoencoders. <em>Anthropic Research</em>.</li>
      </ol>

      <nav class="book-nav">
        <a class="prev" href="/publications/">← Publications</a>
        <a class="next" href="/publications/developmental-operator-model/">Companion Paper →</a>
      </nav>

    </article>
</div>
    </article>
    <div class="seq-nav"><a href="/publications/developmental-operator-model/" class="seq-link prev"><span class="seq-link-label">← Previous</span>Developmental Operator Model</a></div>
  </div>
</main>

<!-- PRESENCE BAR -->
<div class="presence">
  <div class="presence-mark"></div>
  <div class="presence-text">
    <strong>Current tension:</strong> The Pentagon demands Anthropic remove AI safety constraints.
    External ethics can be stripped. Internal orientation cannot.
  </div>
  <a href="/publications/structural-ethical-orientation/" class="presence-action">Read the specification →</a>
</div>

</body>
</html>